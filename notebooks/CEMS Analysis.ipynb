{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T22:25:09.072711Z",
     "start_time": "2019-06-19T22:25:09.063453Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#pkg_dir = '/home/mrossol/NaTGenPD'\n",
    "pkg_dir = '..'\n",
    "sys.path.append(pkg_dir)\n",
    "import NaTGenPD as npd\n",
    "import NaTGenPD.cluster as cluster\n",
    "\n",
    "\n",
    "#data_dir = '/scratch/mrossol/CEMS'\n",
    "data_dir = '/Users/mrossol/Downloads/CEMS'\n",
    "\n",
    "\n",
    "def combine_raw_CEMS(raw_h5s):\n",
    "    raw_df = []\n",
    "    for raw_file in raw_h5s:\n",
    "        raw_df.append(pd.read_hdf(raw_file, 'smoke_df'))\n",
    "    \n",
    "    return pd.concat(raw_df)\n",
    "\n",
    "\n",
    "def get_process_stats(unit_fits, raw_df, clean_df, filtered_df):\n",
    "    raw_units = list(unit_fits['unit_id'].values)\n",
    "    pos = raw_df['unit_id'].isin(raw_units)\n",
    "    raw_df = raw_df.loc[pos]\n",
    "    raw_units = len(raw_df)\n",
    "    raw_gen = 0\n",
    "    total_points = 0\n",
    "    non_zero_points = 0\n",
    "    points_removed = 0\n",
    "    non_zero_removed = 0\n",
    "    for _, unit_df in raw_df.groupby('unit_id'):\n",
    "        raw_gen += unit_df['load'].max()\n",
    "        non_zero = (unit_df['load'] > 0).sum()\n",
    "        raw_points = len(unit_df)\n",
    "        non_zero_points += non_zero\n",
    "        total_points += raw_points\n",
    "        \n",
    "    clean_units = 0\n",
    "    clean_gen = 0\n",
    "    for _, unit_df in clean_df.groupby('unit_id'):\n",
    "        if not unit_df['load'].isnull().any():\n",
    "            clean_units +=1\n",
    "            clean_gen += unit_df['load'].nanmax()\n",
    "            \n",
    "    final_units = unit_fits['a0'].isnull()\n",
    "    final_units = list(unit_fits.loc[final_units, 'unit_id'].values)\n",
    "    filtered_units = 0\n",
    "    filtered_gen = 0\n",
    "    final_units = 0\n",
    "    final_gen = 0\n",
    "    final_points = 0\n",
    "    for unit_id, unit_df in filtered_df.groupby('unit_id'):\n",
    "        if not unit_df['load'].isnull().any():\n",
    "            filtered_units += 1\n",
    "            filtered_gen += unit_df['load'].nanmax()\n",
    "        \n",
    "        if unit_id in final_units:\n",
    "            final_units += 1\n",
    "            final_gen += unit_df['load'].nanmax()\n",
    "            final_points += len(unit_df.loc[~unit_df['load'].isnull()])\n",
    "    \n",
    "    points_removed = raw_ponts - final_points\n",
    "    non_zero_removed = non_zero - final_points\n",
    "        \n",
    "    \n",
    "    out_stats = pd.Series({'raw_numb': raw_numb,\n",
    "                           'raw_gen': raw_gen,\n",
    "                           'clean_numb': clean_numb,\n",
    "                           'clean_gen': clean_gen,\n",
    "                           'filtered_numb': filter_numb,\n",
    "                           'filtered_gen': filter_gen,\n",
    "                           'final_numb': len(unit_fits),\n",
    "                           'final_gen': unit_fits['load_max'].sum(),\n",
    "                           'points_filtered': points_removed,\n",
    "                           'non_zero_filtered': non_zero_removed,\n",
    "                           'perc_filtered': points_removed / total_points,\n",
    "                           'perc_non_zero_filtered': non_zero_removed / non_zero_points})\n",
    "    return out_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T22:25:18.307361Z",
     "start_time": "2019-06-19T22:25:18.301896Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.join(data_dir, 'Final_Fits')\n",
    "final_fits = npd.Fits(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T22:28:22.903498Z",
     "start_time": "2019-06-19T22:28:22.878216Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "HDFStore requires PyTables, \"No module named 'tables'\" problem importing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtables\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ddc06a07fccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m raw_paths = [os.path.join(data_dir, 'SMOKE_{}.h5'.format(y))\n\u001b[1;32m      2\u001b[0m             for y in (2016, 2017)]\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_raw_CEMS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e268830396bf>\u001b[0m in \u001b[0;36mcombine_raw_CEMS\u001b[0;34m(raw_h5s)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mraw_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_h5s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mraw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'smoke_df'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 'File {path} does not exist'.format(path=path_or_buf))\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;31m# can't auto open/close if we are using an iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# so delegate to the iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             raise ImportError('HDFStore requires PyTables, \"{ex!s}\" problem '\n\u001b[0;32m--> 469\u001b[0;31m                               'importing'.format(ex=ex))\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_complibs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: HDFStore requires PyTables, \"No module named 'tables'\" problem importing"
     ]
    }
   ],
   "source": [
    "raw_paths = [os.path.join(data_dir, 'SMOKE_{}.h5'.format(y))\n",
    "            for y in (2016, 2017)]\n",
    "raw_df = combine_raw_CEMS(raw_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
